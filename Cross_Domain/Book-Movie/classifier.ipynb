{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook implements a part of the Cross-Domain Recommendation System, focusing on genre classification and prediction using a pre-trained RoBERTa model. The system maps book genres to a unified genre space and generates recommendations based on user preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook performs the following steps:\n",
    "\n",
    "* Imports and Setup: Loads necessary libraries and downloads NLTK data.\n",
    "* Load Data and Model: Loads genre mappings and the pre-trained RoBERTa model.\n",
    "* Text Preprocessing: Defines a function to clean and preprocess text data.\n",
    "* Prepare Labels: Extracts genre labels for mapping predictions.\n",
    "* Map Predictions: Converts model output to human-readable genres.\n",
    "* Make Predictions: Processes test data, makes predictions, and displays them.\n",
    "* Execute Predictions: Runs the prediction pipeline and displays results.\n",
    "\n",
    "By following these steps, the system can effectively classify book genres and facilitate cross-domain recommendations between books and movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MSI-1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MSI-1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the book genres from a JSON file\n",
    "with open('book_genres.json', 'r') as f:\n",
    "    book_genres = json.load(f)\n",
    "\n",
    "# Load the pre-trained RoBERTa model\n",
    "with open('model-v1.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\['\n",
      "C:\\Users\\MSI-1\\AppData\\Local\\Temp\\ipykernel_6784\\3882086391.py:3: SyntaxWarning: invalid escape sequence '\\['\n",
      "  REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]-')\n"
     ]
    }
   ],
   "source": [
    "# Define regular expressions for text cleaning\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;-]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by:\n",
    "    - Converting to lowercase\n",
    "    - Replacing specific symbols with space\n",
    "    - Removing unwanted symbols\n",
    "    - Removing stopwords\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text)  # Replace specified symbols with space\n",
    "    text = BAD_SYMBOLS_RE.sub('', text)        # Remove unwanted symbols\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)  # Remove stopwords\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fiction',\n",
       " 'Romance',\n",
       " 'Nonfiction',\n",
       " \"Children's\",\n",
       " 'Young Adult',\n",
       " 'Teen',\n",
       " 'Mystery',\n",
       " 'Crime',\n",
       " 'Thriller',\n",
       " 'Fantasy',\n",
       " 'Science Fiction',\n",
       " 'Horror',\n",
       " 'Drama',\n",
       " 'Poetry',\n",
       " 'Art',\n",
       " 'Humor',\n",
       " 'Religion']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract genres from book_genres, excluding the last entry if necessary\n",
    "labels = [x['genre'] for x in book_genres[:-1]]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predictions(predictions):\n",
    "    \"\"\"\n",
    "    Maps binary prediction arrays to their corresponding genre labels.\n",
    "\n",
    "    Args:\n",
    "        predictions (list of lists): Each sublist contains binary indicators for genres.\n",
    "\n",
    "    Returns:\n",
    "        list of lists: Each sublist contains the genres predicted for a book.\n",
    "    \"\"\"\n",
    "    return [[genre for i, genre in enumerate(labels) if prediction[i]] for prediction in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    \"\"\"\n",
    "    Processes the test data, makes genre predictions, and prints the results.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Contains raw predictions, labeled predictions, and model outputs.\n",
    "    \"\"\"\n",
    "    # Read and clean test inputs\n",
    "    with open('test.txt', 'r') as f:\n",
    "        test_inputs = [clean_text(x.strip()) for x in f.readlines()]\n",
    "    \n",
    "    # Make predictions using the pre-trained model\n",
    "    predictions, outputs = model.predict(test_inputs)\n",
    "    \n",
    "    # Map binary predictions to genre labels\n",
    "    labeled_predictions = map_predictions(predictions)\n",
    "    \n",
    "    # Print each set of predicted genres\n",
    "    for p in labeled_predictions:\n",
    "        print(p)\n",
    "    \n",
    "    return predictions, labeled_predictions, outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:07,  7.20s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['Nonfiction']\n",
      "['Fiction', 'Fantasy']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute the prediction function and store results\n",
    "p, lp, o = make_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34887695, 0.07330322, 0.0165863 , 0.0053215 , 0.01327515,\n",
       "       0.00201035, 0.07519531, 0.04302979, 0.09570312, 0.01542664,\n",
       "       0.00734711, 0.00391388, 0.08404541, 0.00069046, 0.00054836,\n",
       "       0.0165863 , 0.00728989])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first element of the model's outputs\n",
    "o[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
